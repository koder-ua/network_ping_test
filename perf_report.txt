## Тут умный заголовок

### Что тестировалось

Различные способы обработки TCP соединений в питоне на предмет:

    * Способности обрабатывать большие количества соединений >=10k
    * Скорости и латентности на малых, средних и больших количествах соединений.

### Описание методики

Тестировалась пересылка коротких(64b) сообщений между
клиентом и сервером в режиме ping-pong в течении фиксированного времени (30s).
Сервер написан на С++ & epoll, исполняется в 3х потоках. Вся статистика
(сообщения, латентности, таймауты) ведется на сервере.

Клиент открывает слушающий сокет, открывает с сервером управляющее соединение
и передает настройки теста. Сервер открывает необходимое количество соединений
с клиентом и начинает пересылать сообщения. Сообщения не начинают пересылаться
пока все затребованные соединения не установленны (есть небольшая проблема с
поведением listen, ее влияние нивелируется дополнительным таймаутом).

По окончанию теста сервер передает клиенту статистику. Клиент замеряет использование
времени в пользовательском режиме и ядром на своей стороне (os.times).

Измерения проводились в двух вариантах - с локальным сервером и с сервером на другой машине, но
в одном сегменте локальной сети.

Все тесты запускались с привязкой питоновского процесса к одному ядру.Без привязки:

    * Питоновские потоки становятся значительно медленее из-за GIL и особенностей шедулинга [6];
    * C++ потоки получили бы приймущество над однопоточными циклами.

Локальные тесты исполнялись по 7 раз, удаленные по 15. 

Код тестов - [7].

Протестированные функции:

    * asyncio - asyncio c потоками. Дефолтный способ использования asyncio [1]
    * asyncio_proto - asyncio на протоколах. Фактически аналог twisted protocols [2]
    * asyncio_sock - asyncio с "сырыми" сокетами, используя ev_loop.sock_recv/ev_loop.sock_sendall
    * gevent - [3]
    * selector - используя один поток и модуль selectors [4]. По умолчанию под линкс используется epoll
    * thread - потоки, по одному потоку на каждого клиента
    * uvloop,uvloop_proto,uvloop_sock - тот же код что и для asyncio,asyncio_proto и asyncio_sock,
        соответсвенно, но вместо asyncio.new_event_loop использовалось uvloop.new_event_loop
        библиотеки uvloop [5]
    * cpp_epoll - c++ модуль с использованием epoll
    * cpp_poll - c++ модуль с использованием poll
    * cpp_th - c++ модуль на потоках. По одному std::thread на каждый сокет.

#### Система:

    * Ubuntu 14.04.1
    * 3.19.0-25-generic #26~14.04.1-Ubuntu x86_64
    * Python 3.5.1
    * Intel(R) Xeon(R) CPU E3-1231 v3 @ 3.40GHz
    * Управление энергопотреблением выключенно, все ядра работали на 3.4Ghz
    * 1Gb Full, Intel Corporation I350 Gigabit Network Connection (rev 01)
    * uvloop 0.4.28.


#### Исполнение тестов

Запуск сервера:

    # ulimit -n 65536
    # echo 1024 65535 | tee /proc/sys/net/ipv4/ip_local_port_range    
    # taskset -c 2,4,6 ./bin/server

Запуск клиента:

    # ulimit -n 65536
    # echo 1024 65535 | tee /proc/sys/net/ipv4/ip_local_port_range    
    # taskset -c 0 python3.5 main.py ....

Использовались только пакеты по 64 байта. Использование больших по размеру пакетов
бессмысленно, посколько код обработки оперирует только указателями на буфер, а 
накладные расходы на передачу данных между буфером и сокетом лежат на операционной
системе и одинаковы для всех вариантов. Также увеличение размеров сообщения приводит
к быстрому насыщению канала связи для нелокальных тестов, что скрывает различия между
тестами.


#### Особенности

    Для тестов asyncio_sock/uvloop_sock(uvloop<0.4.28) с сокетами  и локальным сервером
все соединения делятся на две группы - активные и стагнирующие. Активные постоянно
обслуживаются и обрабатывают основную массу сообщений (>95%) в то время как стагнирующие
крайне редко получали кванты времени и обрабатывали единичные сообщения. В итоге при 20k
соединений активны менее 100, что не позволяет корректно сравнить эти функции с другими.

Причина в этом участке кода (asyncio/selector_events.py:321):

def _sock_recv(self, fut, registered, sock, n):
    ...
    try:
        data = sock.recv(n)
    except (BlockingIOError, InterruptedError):
        ADD_THIS_SOCKET_TO_EPOLL
        CONTINUE_WITH_NEXT_SOCKET
    except Exception as exc:
        set exception to future
        CONTINUE_WITH_THIS_SOCKET
    else:
        set result to future
        CONTINUE_WITH_THIS_SOCKET

Если клиент высокоактивен, то data = sock.recv(n) успешно исполнится
и продолжится обработка текущего сокета.

Это так же поясняет почему для asyncio+socket получается такое низкое количество
вызовов epoll_ctl. В uvloop==0.4.28 это поведение не проявляется.

Сам по себе этот код не является ошибкой и подобная проблемы врядли имеет возможно
возникнуть в реальности, поскольку даже разнесение сервера и клиента на разные машины
приводит к возникновению достаточно большого лага между отсылкой запроса и приходом
ответа. Но данная оптимизация сильно ускоряет вариант, когда данные из сокета
вычитываются порциями (например при разборе протокола, с длинной впереди сообщения).


#### Распределение нагрузки ядро/питон

Процент времени, использумый ядром для обслуживания tcp стека
(по выводу perf record):

uvloop, remote server = 35%
uvloop, local server  = 50%

asyncio, remote server = 20%
asyncio, local server  = 30%

При локальном тестировании сильно вызрастает нагрузка на CPU из ядра,
посколько небходимо обслуживать две стороны tcp стека. Так-же локально
исполняется сервер нагрузки. Это приводит к том, что локальные тесты
показывают меньшую скорость передачи пакетов.

Однако на небольшом количестве сокетов удаленный сервер медленее,
посколько время обработки всех сокетов оказывается меньше
пинга сети. Т.е. возникают промежутки времени, когда система простаивает,
не имея данных ни на одном сокете.


#### Максимальное количество соединений

Рассматриваемые результат ограниченны 60к соединений для тестов,
основанных на [e]poll и 30к соединений для тестов, остнованных на потоках
(потоки см. следующий пункт).

Для IPv4 максимальное количество соединений между двумя IP адресами
по TCP протоколу ограничено количеством портов - 65534. Что-бы оперировать
бОльшим количеством соединений между двумя машинами можно присоединить
дополнительные IP адреса на сетевое устройство, и открыть по одному
серверному сокету на каждый адрес. См. также тут [8].

#### Максимальное количество потоков

Мне не удалось запустить более 30к С++ потоков. Код вылетает по исчерпанию ресурсов.

# echo 1048576 > /proc/sys/vm/max_map_count
# echo 2097152 > /proc/sys/kernel/threads-max

не помогает. Я предполагаю, что нужно ограничить размеры стека для потоков,
но не Python ни C++11 не позволяют это сделать (в posix/boost можно ограничивать
размер стека, но я использовал std::thread).

Python ведет себя нестабильно при 10k+ потоков.


#### Отличия от реальных систем

Основным отличием от реальных систем является почти полное отсутвие задержек в
протоколе. Сервер поддерживает таймауты на сокетах, но эти тесты я еще не довел
до конца. 

Также можно было потюнить TCP стек.


### Тесты скорости:

Сообщений_в_секунду ~ 2.5 * stddev (== 95% интервал). Удаленный сервер.

+---------------+-------------+-------------+-------------+-------------+-------------+
|     Test      |     10      |     100     |     1k      |     10k     |     60k     |
+===============+=============+=============+=============+=============+=============+
|    asyncio    |   36k ~  4% |   42k ~  4% |   39k ~  7% |   26k ~  3% |   18k ~  5% |
| asyncio_proto |   88k ~  6% |  100k ~ 19% |   99k ~ 14% |   75k ~  9% |  110k ~  4% |
| asyncio_sock  |   22k ~  9% |   25k ~  3% |   22k ~  4% |   21k ~  5% |   18k ~  4% |
|   cpp_epoll   |  150k ~ 10% |  610k ~  4% |  590k ~  4% |  320k ~  3% |  300k ~  1% |
|    cpp_th     |  150k ~ 16% |  340k ~  2% |  260k ~  4% |  190k ~  3% |      FF     |
|    gevent     |   88k ~  6% |   89k ~  7% |   75k ~  5% |   64k ~  4% |   67k ~  5% |
|   selector    |  120k ~ 21% |  300k ~  4% |  290k ~  3% |  160k ~  8% |  190k ~  3% |
|    thread     |  130k ~ 17% |  250k ~  3% |  180k ~  4% |  130k ~ 14% |      FF     |
|    uvloop     |   97k ~ 10% |  120k ~  5% |  100k ~  5% |   49k ~  2% |   33k ~  5% |
| uvloop_proto  |  140k ~ 17% |  360k ~  6% |  350k ~  6% |  150k ~  6% |  200k ~  5% |
|  uvloop_sock  |  100k ~  9% |  160k ~  6% |  150k ~  9% |   80k ~  4% |   84k ~  3% |
+---------------+-------------+-------------+-------------+-------------+-------------+

Относительные скорости:

+---------------+----+-----+----+-----+-----+
|     Test      | 10 | 100 | 1k | 10k | 60k |
+===============+====+=====+====+=====+=====+
|    asyncio    |  2 |  2  |  2 |  1  |  1  |
| asyncio_proto |  5 |  6  |  5 |  4  |  6  |
| asyncio_sock  |  1 |  1  |  1 |  1  |  1  |
|   cpp_epoll   |  9 | 34  | 32 | 18  | 17  |
|    cpp_th     |  8 | 19  | 14 | 11  |  FF |
|    gevent     |  5 |  5  |  4 |  4  |  4  |
|   selector    |  7 | 17  | 16 |  9  | 11  |
|    thread     |  7 | 14  | 10 |  8  |  FF |
|    uvloop     |  5 |  7  |  5 |  3  |  2  |
| uvloop_proto  |  8 | 20  | 19 |  9  | 11  |
|  uvloop_sock  |  6 |  9  |  8 |  4  |  5  |
+---------------+----+-----+----+-----+-----+


Сообщений_в_секунду ~ 2.5 * stddev (== 95% интервал). Локальный сервер.

+---------------+-------------+-------------+-------------+-------------+
|     Test      |     10      |     100     |     1k      |     20k     |
+===============+=============+=============+=============+=============+
|       asyncio |   33k ~ 20% |   37k ~ 17% |   37k ~  3% |   23k ~  8% |
| asyncio_proto |   70k ~ 32% |   82k ~ 13% |   84k ~ 13% |  100k ~  4% |
|  asyncio_sock |   68k ~ 44% |   71k ~ 38% |   70k ~ 25% |   75k ~ 43% |
|     cpp_epoll |  420k ~  4% |  470k ~  2% |  380k ~ 12% |  230k ~  1% |
|      cpp_poll |  320k ~ 40% |  370k ~ 34% |  360k ~  6% |  220k ~ 18% |
|        cpp_th |  300k ~  3% |  290k ~ 10% |  180k ~  8% |  130k ~  1% |
|        gevent |   61k ~ 17% |   70k ~ 19% |   63k ~  9% |   61k ~  9% |
|      selector |  200k ~ 21% |  240k ~ 10% |  210k ~  6% |  160k ~ 28% |
|        thread |  230k ~  2% |  210k ~  7% |  140k ~  1% |   70k ~ 89% |
|        uvloop |  100k ~ 12% |  110k ~  8% |   85k ~  7% |   42k ~  4% |
|  uvloop_proto |  270k ~ 15% |  310k ~  7% |  230k ~  6% |  160k ~ 12% |
|   uvloop_sock |  110k ~ 17% |  130k ~  8% |  110k ~  9% |   79k ~  3% |
+---------------+-------------+-------------+-------------+-------------+

Относительные скорости:

+---------------+----+-----+----+-----+
|     Test      | 10 | 100 | 1k | 20k |
+===============+====+=====+====+=====+
|       asyncio |  1 |   2 |  2 |   1 |
| asyncio_proto |  3 |   4 |  4 |   5 |
|  asyncio_sock |  3 |   3 |  3 |   3 |
|     cpp_epoll | 19 |  21 | 17 |  10 |
|      cpp_poll | 14 |  16 | 16 |  10 |
|        cpp_th | 13 |  13 |  8 |   6 |
|        gevent |  3 |   3 |  3 |   3 |
|      selector |  9 |  11 |  9 |   7 |
|        thread | 10 |   9 |  6 |   3 |
|        uvloop |  4 |   5 |  4 |   2 |
|  uvloop_proto | 12 |  14 | 10 |   7 |
|   uvloop_sock |  5 |   6 |  5 |   3 |
+---------------+----+-----+----+-----+


#### Обсуждение

Общее распределение по убыванию скоростей примерно такое:

    * cpp_epoll
    * uvloop_proto, selector
    * cpp_th
    * thread
    * uvloop, asyncio_proto
    * gevent
    * asyncio, asyncio_sock


Выводы по скорости:
    * Ни asyncio, ни uvloop в варианте с потоками не могут притендовать на звание "быстрой платформы"
    * И asyncio и uvloop тратят больше времени на свои накладные расходы, чем на реальную работу
      (за исключением uvloop_proto, но о нем ниже)
    * По мере роста количества соединений скорости у всех более-менее быстрых вариантов проседают
    * Скорости вариантов на потоках и asyncio/uvloop падают быстрее всего
    * Даже на 20k соединений потоки все еще в разы быстрее и asyncio/uvloop
    * uvloop во всех вариантах и режимах в 2.5-3 раза быстрее, чем asyncio, при (наверное) полной совместимости
    * gevent весьма медленный
    * asyncio/uvloop на потоках устанавливают соединения сильно медленее других функций
    * 100 потоков быстрее 10 по описаным в разделе 'Распределение нагрузки ядро/питон' причинам
    * uvloop_proto показывает очень высокие скорости (~1.5 медленнее С++) за счет
      избавления от практически всех накладных расходов. Но его API копирует "старый"
      twisted, т.е. хорошо подходит только для очень ограниченного количества простых
      протоколов общения с одним клиентом. Фактически оно бесполезно для подавляющего
      большинства программ, и в любом случае лишено все преймуществ yield-based API.
    * Тесты на локальной машине показали довольно высокий разброс

Несмотря на то, что потоки показывают неплохую (по меркам питона) производительность
под нагрузками у них есть много минусов: сильный разброс латентности, сложно
контролировать, мониторить и отлаживать систему, etc.

Также иногда тест с питон потоками просто прекращал исполняться, съедал 100% процессора
и висел.


#### Латентность

Латентность медианная (удаленный сервер):

+---------------+--------+--------+-------+--------+--------+
|     Test      |   10   |  100   |  1k   |  10k   |  60k   |
+===============+========+========+=======+========+========+
|    asyncio    | 263 us |   2 ms | 24 ms | 336 ms |  >1s   |
| asyncio_proto | 100 us | 898 us |  9 ms | 123 ms | 482 ms |
| asyncio_sock  | 427 us |   3 ms | 43 ms | 467 ms |  >1s   |
|   cpp_epoll   |  46 us | 147 us |  1 ms |  29 ms | 189 ms |
|    cpp_th     |  49 us | 244 us |  3 ms |  47 ms |   FF   |
|    gevent     |  99 us |   1 ms | 12 ms | 146 ms | 828 ms |
|   selector    |  80 us | 252 us |  3 ms |  55 ms | 295 ms |
|    thread     |  65 us | 345 us |  4 ms |  64 ms |   FF   |
|    uvloop     |  93 us | 794 us |  9 ms | 184 ms |  >1s   |
| uvloop_proto  |  56 us | 271 us |  2 ms |  59 ms | 243 ms |
|  uvloop_sock  |  92 us | 564 us |  6 ms | 125 ms | 660 ms |
+---------------+--------+--------+-------+--------+--------+


Латентность 95й персентиль (удаленный сервер):

+---------------+--------+--------+-------+--------+--------+
|     Test      |   10   |  100   |  1k   |  10k   |  60k   |
+===============+========+========+=======+========+========+
|    asyncio    | 333 us |   2 ms | 25 ms | 458 ms |  >1s   |
| asyncio_proto | 149 us |   1 ms |  9 ms | 164 ms | 569 ms |
| asyncio_sock  | 450 us |   3 ms | 54 ms | 484 ms |  >1s   |
|   cpp_epoll   |  98 us | 197 us |  1 ms |  31 ms | 218 ms |
|    cpp_th     |  99 us | 454 us |  5 ms |  69 ms |   FF   |
|    gevent     | 157 us |   1 ms | 13 ms | 197 ms | 884 ms |
|   selector    |  99 us | 493 us |  3 ms |  73 ms | 322 ms |
|    thread     |  99 us | 610 us |  6 ms | 110 ms |   FF   |
|    uvloop     | 128 us | 809 us | 11 ms | 280 ms |  >1s   |
| uvloop_proto  |  98 us | 306 us |  2 ms |  72 ms | 482 ms |
|  uvloop_sock  |  99 us |   1 ms |  6 ms | 158 ms | 872 ms |
+---------------+--------+--------+-------+--------+--------+

Латентность согласуется с mps. В целом фунции, основанные на epoll/poll
циклах показывают меньший разброс латентности, чем основанные на потоках,
но отличие невелико.


#### Совершаемые системные вызовы

Все измерения проводились с помошью 'sudo perf stat -e '*' ....' на 100 соединениях.

Для тестов asyncio, asyncio_sock, uvloop, uvloop_sock, gevent время
затрачиваемое на системные вызовы в 2-3 раза меньше, чем время работы
внутри библиотеки, поэтому состав вызовов для них играет меньшую роль в
производительности, но все равно помогает понять что внутри происходит.

тип_теста = количество_вызовов_на_один_пинг


thread(no affinity) = sendto + recvfrom + 15 * futex
Основную часть времени система мучала GIL

thread(affinity) = sendto + recvfrom + 0.01 * futex

selector = sendto + recvfrom + 0.01 * epoll_wait

asyncio = sendto + recvfrom + mremap + munmap + mmap + 0.02 * epoll_wait
    Откуда берутся лишние обращения к mXXmap мне не понятно

asyncio_proto = sendto + recvfrom + mremap + munmap + mmap + 0.01 * epoll_wait
    Те же странные mXXmap, что и в asyncio

asyncio_sock = sendto + recvfrom + 0.04 * epoll_ctl
    По идее asyncio_sock должна делать 2 вызова epoll_ctl на каждый
    recvfrom, но из-за описанной выше опитимизации этого не происходит.

uvloop = read + write + 0.01 * epoll_wait

uvloop_sock = 2 * epoll_ctl + sendto + recvfrom + 0.01 * epoll_wait

uvloop_proto = read + write + 0.01 * epoll_wait

cpp_th = recvfrom + write

cpp_poll = recvfrom + write + 0.01 * poll

cpp_epoll = recvfrom + write + 0.01 * epoll_wait

gevent = 2 * recvfrom + sendto + 0.01 * epoll_wait


#### Доля времени, проведенные в user mode во время теста (округлено до 5-10%):

Значения для других количеств соединений отличаются от этих очень слабо (в пределах погрешности).

+---------------+----+
|     Test      | 1k |
+===============+====+
|       asyncio | 90 |
| asyncio_proto | 50 |
|  asyncio_sock | 90 |
|     cpp_epoll |  5 |
|      cpp_poll |  5 |
|        cpp_th |  5 |
|        gevent | 80 |
|      selector | 60 |
|        thread | 30 |
|        uvloop | 80 |
|  uvloop_proto | 40 |
|   uvloop_sock | 70 |
+---------------+----+


#### Полезные ссылки

   * Asyncio build in 45m - https://www.youtube.com/watch?v=MCs5OvhV9S
   * Concurrency is not parallelism - https://blog.golang.org/concurrency-is-not-parallelism
   * Отличный доклад о тестах производительности - https://www.youtube.com/watch?v=zWxSZcpeS8Q
   * С10K problem - http://www.kegel.com/c10k.html
   * C10M problem - http://c10m.robertgraham.com/p/manifesto.html
   * How far epoll can push concurrent socket connection - http://shenfeng.me/how-far-epoll-can-push-concurrent-socket-connection.html
   * Акторы в скале - [9], [10], [11]
   * Кусок эппопеи с шедулерами в Go - https://morsmachine.dk/go-scheduler
   * Twisted & asyncio - https://glyph.twistedmatrix.com/2014/05/the-report-of-our-death.html


[1] https://docs.python.org/3/library/asyncio-stream.html#tcp-echo-client-using-streams
[2] https://docs.python.org/3/library/asyncio-protocol.html#tcp-echo-client-protocol
[3] http://www.gevent.org/
[4] https://docs.python.org/3/library/selectors.html
[5] https://github.com/MagicStack/uvloop
[6] https://www.mirantis.com/blog/improve-performance-python-programs-restricting-single-cpu/
[7] https://github.com/koder-ua/network_ping_test
[8] https://mrotaru.wordpress.com/2013/10/10/scaling-to-12-million-concurrent-connections-how-migratorydata-did-it/
[9] http://danielwestheide.com/blog/2013/02/27/the-neophytes-guide-to-scala-part-14-the-actor-approach-to-concurrency.html
[10] http://danielwestheide.com/blog/2013/03/20/the-neophytes-guide-to-scala-part-15-dealing-with-failure-in-actor-systems.html
[11] http://doc.akka.io/docs/akka/snapshot/scala/actors.html
